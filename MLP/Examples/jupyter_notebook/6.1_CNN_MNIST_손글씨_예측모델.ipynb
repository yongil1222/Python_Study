{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서플로우로 CNN 실습하기\n",
    "텐서플로우로 아래 그림과 동일한 CNN을 직접 구현하고, MNIST 손글씨로 학습 및 테스트를 진행보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/practice_cnn.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/practice_cnn.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습데이터에서 검증 데이터 분리하기\n",
    "학습 중간마다 검증 데이터로 모델의 성능을 측정하면 다음과 같은 장점이 있습니다.  \n",
    "1) 모델 학습이 제대로 진행되는 지 검증 정확도로 확인할 수 있습니다.  \n",
    "2) 학습 정확도는 올라가는 데 검증 정확도가 안올라가거나 떨어질 시, 조기 종료를 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val  = x_train[50000:60000]\n",
    "x_train = x_train[0:50000]\n",
    "y_val  = y_train[50000:60000]\n",
    "y_train = y_train[0:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data has 50000 samples\n",
      "every train data is 28 * 28 image\n"
     ]
    }
   ],
   "source": [
    "print(\"train data has \" + str(x_train.shape[0]) + \" samples\")\n",
    "print(\"every train data is \" + str(x_train.shape[1]) \n",
    "      + \" * \" + str(x_train.shape[2]) + \" image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation data has 10000 samples\n",
      "every train data is 28 * 28 image\n"
     ]
    }
   ],
   "source": [
    "print(\"validation data has \" + str(x_val.shape[0]) + \" samples\")\n",
    "print(\"every train data is \" + str(x_val.shape[1]) \n",
    "      + \" * \" + str(x_train.shape[2]) + \" image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0** 부터 **255** 까지의 그레이 스케일을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "# sample to show gray scale values\n",
    "print(x_train[0][8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0** 부터 **9**까지의 이미지에 해당하는 숫자를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 1 9 2 1 3 1]\n"
     ]
    }
   ],
   "source": [
    "# sample to show labels for first train data to 10th train data\n",
    "print(y_train[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "테스트 데이터는 **10000** 개의 샘플을 가지고 있습니다.  \n",
    "모든 테스트 데이터는 **28 * 28** 의 이미지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data has 10000 samples\n",
      "every test data is 28 * 28 image\n"
     ]
    }
   ],
   "source": [
    "print(\"test data has \" + str(x_test.shape[0]) + \" samples\")\n",
    "print(\"every test data is \" + str(x_test.shape[1]) \n",
    "      + \" * \" + str(x_test.shape[2]) + \" image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 구조 변경하기\n",
    "입력 레이어에 데이터를 넣기 위해서 데이터의 구조를 변경해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = np.reshape(x_train, (50000,28,28,1))\n",
    "x_val = np.reshape(x_val, (10000,28,28,1))\n",
    "x_test = np.reshape(x_test, (10000,28,28,1))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 정규화\n",
    "데이터 정규화는 보통 학습 시간을 단축하고, 더 나은 성능을 구하도록 도와줍니다.  \n",
    "MNIST 데이터의 모든 값은 0부터 255의 범위 안에 있으므로, 255로 값을 나눠줌으로써, 모든 값을 0부터 1 사이의 값으로 정규화합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "gray_scale = 255\n",
    "x_train /= gray_scale\n",
    "x_val /= gray_scale\n",
    "x_test /= gray_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실제값을 one hot encoding으로 변경하기\n",
    "손실 함수에서 크로스 엔트로피를 계산하기 위해, 실제값은 one hot encoding 값으로 변경합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN 텐서플로우로 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/practice_cnn.png\" width=\"800\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://raw.githubusercontent.com/captainchargers/deeplearning/master/img/practice_cnn.png\", width=800, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터 형태 그대로 28 X 28의 포맷을 그대로 입력 데이터로 사용합니다.  \n",
    "타겟은 0부터 9까지의 숫자입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 파라미터(weight, bias) 초기값을 설정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding='SAME'은 레이어에 입력된 피쳐맵의 사이즈와 동일하게 피쳐맵을 출력하도록 설정해줍니다.\n",
    "예를 들어, CONV1에 28 X 28의 이미지 데이터가 입력되면, 동일한 크기인 28 X 28 형태의 피쳐맵이 출력되게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 CONV 레이어는 총 16개의 필터를 가지고 있고 필터의 사이즈는 5 X 5입니다.\n",
    "편향값(bias)는 필터의 갯수만큼 만들어줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 16])\n",
    "b_conv1 = bias_variable([16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "활성화함수로 relu를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x, W_conv1) + b_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONV 레이어 다음으로 풀링 레이어를 적용하여 activation map의 크기를 줄여줍니다. activation map의 크기를 줄여줌으로써, 파라미터가 줄어들어 모델 크기가 작아지고, 과대적합의 위험도 감소시켜줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "풀링레이어의 영향으로, activation map의 사이즈는 14 X 14가 되었습니다. 이 값은 다음에 이어지는 CONV2의 입력으로 들어가게 됩니다. CONV2는 총 32개의 필터를 가지고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 16, 32])\n",
    "b_conv2 = bias_variable([32])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "풀링레이어 이후의 activation map의 사이즈는 7 X 7이 됩니다.  \n",
    "\n",
    "#### FC (Fully Connected Layer)\n",
    "FC는 CONV를 통해 추출된 이미지의 특징들을 입력으로 받아 0부터 9까지의 숫자 중 하나로 이미지를 분류합니다.\n",
    "아래 코드에서 tf.reshape를 사용하여 모든 특징들을 하나의 배열로 형변환합니다. 형변환된 특징들은 FC의 입력값이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 32, 128])\n",
    "b_fc1 = bias_variable([128])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*32])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FC 영역에는 FC1, FC2 총 2개의 히든 레이어가 존재합니다. FC1은 128개의 노드, FC2에는 10개의 노드가 존재합니다. FC2에 10개의 노드가 존재하는 이유는 FC2의 10개 노드의 값들을 소프트맥스에 입력시켜서 각 노드별 확률을 구하기 위해서입니다. 각 노드는 숫자 0부터 9를 의미하며, 이 예측값은 크로스 엔트로피를 통해 실제값과의 차이를 계산하는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([128, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같이 크로스엔트로피를 설정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        labels=y_, logits=y_conv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아담 옵티마이저를 사용해서 모델을 최적화합니다. 학습률은 0.001로 설정하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드는 정확도를 구하기 위해서 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 및 테스트\n",
    "이제 CNN 모델을 MNIST 데이터로 학습해보도록 하겠습니다. 단 3번의 주기만으로도 놀라온 정확도가 확인됩니다. 이번 실습에서는 미니배치를 사용하여 모델을 최적화합니다. 미니배치는 총 500개의 학습데이터가 들어있고, 미니배치마다 파라미터를 조정해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train acc: 0.11\n",
      "step 10: train acc: 0.646\n",
      "step 20: train acc: 0.83\n",
      "step 30: train acc: 0.866\n",
      "step 40: train acc: 0.89\n",
      "step 50: train acc: 0.914\n",
      "step 60: train acc: 0.92\n",
      "step 70: train acc: 0.942\n",
      "step 80: train acc: 0.94\n",
      "step 90: train acc: 0.926\n",
      "validation accuracy: 0.9535\n",
      "step 0: train acc: 0.948\n",
      "step 10: train acc: 0.952\n",
      "step 20: train acc: 0.946\n",
      "step 30: train acc: 0.958\n",
      "step 40: train acc: 0.958\n",
      "step 50: train acc: 0.972\n",
      "step 60: train acc: 0.968\n",
      "step 70: train acc: 0.968\n",
      "step 80: train acc: 0.972\n",
      "step 90: train acc: 0.97\n",
      "validation accuracy: 0.9717\n",
      "step 0: train acc: 0.968\n",
      "step 10: train acc: 0.982\n",
      "step 20: train acc: 0.96\n",
      "step 30: train acc: 0.966\n",
      "step 40: train acc: 0.982\n",
      "step 50: train acc: 0.976\n",
      "step 60: train acc: 0.978\n",
      "step 70: train acc: 0.97\n",
      "step 80: train acc: 0.978\n",
      "step 90: train acc: 0.97\n",
      "validation accuracy: 0.9787\n",
      "test accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# train hyperparameters\n",
    "epoch_cnt = 3\n",
    "batch_size = 500\n",
    "iteration = len(x_train) // batch_size\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    tf.set_random_seed(777)\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    for epoch in range(epoch_cnt):\n",
    "        avg_loss = 0.\n",
    "        start = 0; end = batch_size\n",
    "        \n",
    "        for i in range(iteration):\n",
    "            if i%10 == 0:\n",
    "                train_acc = accuracy.eval(\n",
    "                        feed_dict={x:x_train[start: end], \n",
    "                                    y_: y_train[start: end]})\n",
    "                print(\"step \"+str(i)+ \": train acc: \"+str(train_acc))\n",
    "            train_step.run(\n",
    "                feed_dict={\n",
    "                    x:x_train[start: end], y_: y_train[start: end]})\n",
    "            start += batch_size; end += batch_size    \n",
    "        \n",
    "        # Validate model\n",
    "        val_accuracy = accuracy.eval(feed_dict={x:x_val, y_: y_val})\n",
    "        print(\"validation accuracy: \"+str(val_accuracy))\n",
    "        \n",
    "    test_accuracy = accuracy.eval(feed_dict={x:x_test, y_: y_test}) \n",
    "    print(\"test accuracy: \"+str(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "단 **3** 번의 주기만으로도, **97.7%** 의 정확도를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
