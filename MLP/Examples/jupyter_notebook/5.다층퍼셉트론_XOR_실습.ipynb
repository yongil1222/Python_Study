{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다층퍼셉트론 XOR 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "텐서플로우로 직접 다층퍼셉트론을 구현하여 XOR 연산을 다뤄보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 텐서플로우 그래프 정의하기\n",
    "가장 먼저 입력 레이어를 정의하겠습니다.  \n",
    "XOR 연산 입력 데이터를 X, 결과값을 Y라고 정의하겠습니다.  \n",
    "\n",
    "XOR 연산을 위해 입력값 X는 아래와 같이 [4,2]의 형태를 갖습니다.\n",
    "  \n",
    "[0, 0],  \n",
    "[0, 1],  \n",
    "[1, 0],  \n",
    "[1, 1]  \n",
    "\n",
    "입력값에 따른 출력값 Y는 [4,1]의 형태를 갖습니다.    \n",
    "[[0], [1], [1], [0]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[4,2])\n",
    "Y = tf.placeholder(tf.float32, shape=[4,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 첫번째 히든 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두개의 입력값을 받는 두개의 뉴론을 만듭니다.  \n",
    "W1 = tf.Variable(tf.random_uniform([2,2]))\n",
    "# 각각의 뉴론은 한개의 편향값을 갖습니다.\n",
    "B1 = tf.Variable(tf.zeros([2]))\n",
    "# 출력값으로 Z를 리턴하도록 합니다. sigmoid(W1 * X + B1)\n",
    "Z = tf.sigmoid(tf.matmul(X, W1) + B1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 두번째 히든 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z를 입력값으로 받는 하나의 뉴론을 두번째 히든레이어에 만듭니다.\n",
    "W2 = tf.Variable(tf.random_uniform([2,1]))\n",
    "# 뉴론은 한개의 편향값을 갖습니다.\n",
    "B2 = tf.Variable(tf.zeros([1]))\n",
    "# 출력값으로 Y_hat을 리턴합니다. sigmoid(W2 * Z + B2)\n",
    "Y_hat = tf.sigmoid(tf.matmul(Z, W2) + B2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실 함수\n",
    "크로스 엔트로피를 손실함수로 사용하도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy\n",
    "loss = tf.reduce_mean(-1*((Y*tf.log(Y_hat))+((1-Y)*tf.log(1.0-Y_hat))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적화\n",
    "경사하강법으로 모델의 매개변수(가중치, 편향값)을 최적화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경사하강법\n",
    "train_step = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터를 만듭니다.\n",
    "train_X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "train_Y = [[0],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
      "Epoch :  0\n",
      "Output :  [[0.5230039]\n",
      " [0.524582 ]\n",
      " [0.5268023]\n",
      " [0.5280755]]\n",
      "Epoch :  5000\n",
      "Output :  [[0.44640082]\n",
      " [0.51405567]\n",
      " [0.52132326]\n",
      " [0.5457807 ]]\n",
      "Epoch :  10000\n",
      "Output :  [[0.13913684]\n",
      " [0.76280355]\n",
      " [0.762544  ]\n",
      " [0.36348855]]\n",
      "Epoch :  15000\n",
      "Output :  [[0.04414607]\n",
      " [0.96044695]\n",
      " [0.96046036]\n",
      " [0.04712832]]\n",
      "Final Output :  [[0.02394469]\n",
      " [0.98076755]\n",
      " [0.9807724 ]\n",
      " [0.02158156]]\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로우 매개변수를 초기화를 선언합니다.\n",
    "init = tf.global_variables_initializer()\n",
    "# 학습을 시작합니다.\n",
    "with tf.Session() as sess:\n",
    "    # 매개변수를 초기화합니다.\n",
    "    sess.run(init)\n",
    "    print(\"train data: \"+str(train_X))\n",
    "    # 2만번의 반복학습을 진행합니다.\n",
    "    for i in range(20000):\n",
    "        sess.run(train_step, feed_dict={X: train_X, Y: train_Y})\n",
    "        if i % 5000 == 0:\n",
    "            print('Epoch : ', i)\n",
    "            print('Output : ', sess.run(Y_hat, feed_dict={X: train_X, Y: train_Y}))\n",
    "    \n",
    "    print('Final Output : ', sess.run(Y_hat, feed_dict={X: train_X, Y: train_Y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 결과를 통해, [0,0], [1,1]은 0에 상당히 가까운 값을 출력하고,  \n",
    "[0,1], [1,0]은 1에 상당히 가까운 값을 출력하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
